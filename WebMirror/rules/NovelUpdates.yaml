rewalk_disabled: True

rewalk_interval_days: 50000


FOLLOW_GOOGLE_LINKS: False
allImages: False

type: "eastern"

baseUrl: [
	"https://www.novelupdates.com",
	]

send_raw_feed: False
trigger: False

badwords: [

			'/more-reviews/',
			'/comment-page-',
			'/readlist/',
			'/extnu/',
			'/register/',
			'/user/',

			# Apparently it's built on top of wordpress?
			# Wat?
			'/wp-includes/',
			'/fdrev/',
			'/login/',

			'/lostpassword/',
			'/rank-graph/',
			'/feed/',

			'status=111',
			'status=311',
			'status=211',
			'111111',

			# Don't actually spider the site, just let the update triggers
			# do their thing.
			# 'www.novelupdates.com',
			]

# Content Stripping needs to be determined.
decomposeBefore: [

]

decompose: [
]

stripTitle: []


destyle : [
]


preserveAttrs : [
]

special_case_filters : {

	# # Apparently they don't like bots. Well, too bad.
	"www.novelupdates.com" : ["c_web_request_fetch", ],
	# "www.novelupdates.com" : ["rate_limit", 1],
	# "novelupdates.com"     : ["rate_limit", 1],

	# # So I can test against someone less bot-sensitive
	# "www.google.com" : ["rate_limit", 20],
}


skip_filters : [
	['www.novelupdates.com', "^https?://www\\.novelupdates\\.com(?:/series/[a-zA-Z0-9\\-]+/|/)?$", True],
]

